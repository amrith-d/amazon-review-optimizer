"""
Week 1 Full Demo: Enhanced with Smart Router V2
Real OpenRouter API calls with enhanced routing, progress tracking, and KV optimization
Now includes: Content complexity scoring, cost-optimized routing, real-time progress
"""

import os
import asyncio
import time
import json
import gc
import aiohttp
from datetime import datetime
from dotenv import load_dotenv
from openrouter_integration import OpenRouterOptimizer
from cost_reporter import CostTracker
from main import AmazonDataLoader, SemanticCache
from smart_router_v2 import SmartRouterV2

# Load environment variables
load_dotenv()

class Week1FullOptimizer:
    """Enhanced Week 1 optimizer with Smart Router V2 and progress tracking"""
    
    def __init__(self, max_budget: float = 5.00):
        self.max_budget = max_budget
        os.environ['MAX_BUDGET'] = str(max_budget)
        
        # Initialize components
        self.api_optimizer = OpenRouterOptimizer()
        self.cost_tracker = CostTracker()
        self.data_loader = AmazonDataLoader()
        self.semantic_cache = SemanticCache(max_size=2000)
        self.smart_router = SmartRouterV2()  # Enhanced routing with complexity scoring
        
        # Conversation contexts for KV cache optimization
        self.conversation_contexts = {}
        
        # Timeout and concurrency settings
        self.timeout_settings = {
            'per_review': 30.0,
            'per_batch': None,  # Calculated dynamically
            'retry_attempts': 3,
            'semaphore_limit': 5
        }
        
        print(f"‚úÖ Week 1 Full Optimizer initialized (Budget: ${max_budget})")
        print(f"   ‚Ä¢ Timeout Protection: {self.timeout_settings['per_review']}s per review")
        print(f"   ‚Ä¢ Concurrent Processing: {self.timeout_settings['semaphore_limit']} simultaneous requests")
        print(f"   ‚Ä¢ Retry Logic: {self.timeout_settings['retry_attempts']} attempts with exponential backoff")
    
    def _get_conversation_context(self, category: str) -> list:
        """Get or create conversation context for KV cache optimization"""
        if category not in self.conversation_contexts:
            system_prompts = {
                "Electronics": "You are an expert at analyzing electronics product reviews. Focus on technical features, performance, and value.",
                "Books": "You are an expert at analyzing book reviews. Focus on content quality, readability, and reader satisfaction.", 
                "Home_and_Garden": "You are an expert at analyzing home and garden product reviews. Focus on utility, durability, and practical value."
            }
            
            self.conversation_contexts[category] = [
                {"role": "system", "content": system_prompts.get(category, "You are an expert product review analyst.")}
            ]
        
        return self.conversation_contexts[category]
    
    async def analyze_review_with_full_optimization(self, review: dict) -> dict:
        """Analyze single review with all optimizations"""
        start_time = time.time()
        
        review_text = review['review_text']
        category = review['category']
        
        # Layer 1: Semantic Cache Check
        cached_result = self.semantic_cache.get(review_text, category)
        if cached_result:
            # Semantic cache hit - completely free
            self.cost_tracker.log_api_call(
                model='cache_hit',
                tokens_input=0,
                tokens_output=0,
                cost_usd=0.0,
                category=category,
                cache_hit=True,
                processing_time=time.time() - start_time
            )
            
            return {
                'review_id': review.get('review_id', 'unknown'),
                'category': category,
                'sentiment': cached_result.sentiment,
                'model_used': 'semantic_cache',
                'cost': 0.0,
                'processing_time': time.time() - start_time,
                'semantic_cache_hit': True,
                'kv_cache_hit': False,
                'tokens_used': 0
            }
        
        # Layer 2: Enhanced Smart Routing V2 + KV Cache Optimization
        routing_result = self.smart_router.route_review(review_text, category)
        model_tier = routing_result['recommended_tier']
        complexity_score = routing_result['complexity_analysis']['final']
        
        # Prepare conversation context for KV cache optimization
        conversation_context = self._get_conversation_context(category)
        
        # Create optimized prompt with context
        user_prompt = f"""Analyze this {category.lower()} review:

Product: {review.get('product_title', 'Product')}
Rating: {review.get('rating', 'N/A')}/5
Review: "{review_text}"

Provide brief analysis: sentiment (Positive/Negative/Neutral), quality assessment, and key insight."""
        
        # Use conversation context (KV cache optimization)
        messages = conversation_context + [{"role": "user", "content": user_prompt}]
        
        try:
            # Make API call with conversation context
            model_config = self.api_optimizer._get_model_config(model_tier)
            model_name = model_config['openrouter_name']
            
            response = await asyncio.to_thread(
                self.api_optimizer.client.chat.completions.create,
                model=model_name,
                messages=messages,
                max_tokens=100,
                temperature=0.1
            )
            
            # Calculate costs
            tokens_used = response.usage.total_tokens if response.usage else 100
            cost_per_million = model_config['cost_per_million_tokens']
            actual_cost = (tokens_used / 1_000_000) * cost_per_million
            
            # Update conversation context for next KV cache optimization
            assistant_response = response.choices[0].message.content
            conversation_context.extend([
                {"role": "user", "content": user_prompt},
                {"role": "assistant", "content": assistant_response}
            ])
            
            # Trim context if too long (memory management)
            if len(conversation_context) > 15:
                conversation_context[:] = [conversation_context[0]] + conversation_context[-14:]
                # Force garbage collection to prevent memory leaks
                gc.collect()
            
            # Track cost
            kv_cache_benefit = len(conversation_context) > 3  # Context reused
            self.cost_tracker.log_api_call(
                model=model_name,
                tokens_input=tokens_used // 2,
                tokens_output=tokens_used // 2,
                cost_usd=actual_cost,
                category=category,
                cache_hit=False,
                processing_time=time.time() - start_time
            )
            
            # Update budget tracking
            self.api_optimizer.openrouter_config.current_spend += actual_cost
            
            # Extract sentiment from response
            sentiment = 'Neutral'
            response_lower = assistant_response.lower()
            if 'positive' in response_lower:
                sentiment = 'Positive'
            elif 'negative' in response_lower:
                sentiment = 'Negative'
            
            # Create result for semantic caching
            from main import ProductReviewResult
            cache_result = ProductReviewResult(
                product_category=category,
                sentiment=sentiment,
                product_quality='Good' if review.get('rating', 3) >= 4 else 'Fair',
                purchase_recommendation='Recommend' if review.get('rating', 3) >= 4 else 'Neutral',
                key_insights=[assistant_response[:100]],
                cost=actual_cost,
                model_used=model_name,
                cache_hit=False,
                processing_time=time.time() - start_time
            )
            
            # Cache for future semantic hits
            self.semantic_cache.set(review_text, category, cache_result)
            
            return {
                'review_id': review.get('review_id', 'unknown'),
                'category': category,
                'sentiment': sentiment,
                'model_used': model_name,
                'cost': actual_cost,
                'processing_time': time.time() - start_time,
                'semantic_cache_hit': False,
                'kv_cache_hit': kv_cache_benefit,
                'tokens_used': tokens_used,
                'response_preview': assistant_response[:100],
                'complexity_score': complexity_score,
                'routing_tier': model_tier,
                'routing_reasoning': routing_result['reasoning']
            }
            
        except Exception as e:
            print(f"‚ùå API call failed: {e}")
            return None
    
    async def _process_review_with_timeout_protection(self, review: dict) -> dict:
        """Process single review with timeout protection and retry logic"""
        for attempt in range(self.timeout_settings['retry_attempts']):
            try:
                result = await asyncio.wait_for(
                    self.analyze_review_with_full_optimization(review),
                    timeout=self.timeout_settings['per_review']
                )
                return result
            except asyncio.TimeoutError:
                if attempt == self.timeout_settings['retry_attempts'] - 1:  # Last attempt
                    print(f"‚ö†Ô∏è Review timed out after {self.timeout_settings['retry_attempts']} attempts")
                    return None
                await asyncio.sleep(2 ** attempt)  # Exponential backoff
            except Exception as e:
                print(f"‚ùå Error processing review (attempt {attempt + 1}): {e}")
                if attempt == self.timeout_settings['retry_attempts'] - 1:
                    return None
                await asyncio.sleep(1)
        return None
    
    async def _process_batch_concurrent(self, reviews: list) -> list:
        """Process batch with concurrent processing and timeout protection"""
        semaphore = asyncio.Semaphore(self.timeout_settings['semaphore_limit'])
        
        async def process_with_semaphore(review):
            async with semaphore:
                return await self._process_review_with_timeout_protection(review)
        
        # Create tasks for concurrent processing
        tasks = [process_with_semaphore(review) for review in reviews]
        
        # Calculate dynamic batch timeout
        batch_timeout = len(reviews) * (self.timeout_settings['per_review'] + 5.0)
        
        try:
            results = await asyncio.wait_for(
                asyncio.gather(*tasks, return_exceptions=True),
                timeout=batch_timeout
            )
            
            # Filter successful results
            successful_results = [
                result for result in results 
                if result is not None and not isinstance(result, Exception)
            ]
            
            # Force garbage collection after each batch
            gc.collect()
            
            return successful_results
            
        except asyncio.TimeoutError:
            print(f"‚ùå Entire batch timed out after {batch_timeout:.0f}s")
            return []
    
    async def _load_with_progress_tracking(self, category: str, sample_size: int, current_total: int, target_total: int) -> list:
        """Load data with smooth progress tracking for 1000-review target"""
        print(f"üîÑ Connecting to dataset for {category} reviews...", flush=True)
        
        try:
            reviews = self.data_loader.load_sample_data_streaming(
                category=category,
                sample_size=sample_size,
                batch_size=50  # Load in chunks for progress
            )
            
            # Show progress for every 50 reviews loaded within this category
            loaded_in_category = 0
            progress_reviews = []
            
            for i, review in enumerate(reviews):
                progress_reviews.append(review)
                loaded_in_category += 1
                
                # Show progress every 50 reviews
                if loaded_in_category % 50 == 0 or loaded_in_category == len(reviews):
                    total_so_far = current_total + loaded_in_category
                    percentage = (total_so_far / target_total) * 100
                    print(f"üìä Progress: {total_so_far}/{target_total} reviews loaded ({percentage:.1f}%)", flush=True)
            
            return progress_reviews
            
        except Exception as e:
            print(f"‚ö†Ô∏è Streaming failed for {category}: {e}", flush=True)
            return self.data_loader.load_sample_data(category, sample_size=sample_size)
    
    async def process_week1_batch(self, reviews: list, batch_size: int = 20) -> list:
        """Process Week 1 reviews with smooth progress tracking every 50 reviews"""
        results = []
        total_reviews = len(reviews)
        total_batches = total_reviews // batch_size + (1 if total_reviews % batch_size else 0)
        
        print(f"\nüöÄ Processing {total_reviews} Reviews with Enterprise Progress Tracking")
        print(f"üìä Progress will be shown every 50 reviews until 100% completion")
        print(f"=" * 70)
        print(f"üîÑ Concurrent Processing: {self.timeout_settings['semaphore_limit']} simultaneous requests")
        print(f"üõ°Ô∏è Timeout Protection: {self.timeout_settings['per_review']}s per review with retry logic")
        print(f"‚ö° Processing {total_reviews} reviews in {total_batches} optimized batches...")
        
        for i in range(0, len(reviews), batch_size):
            batch = reviews[i:i + batch_size]
            batch_num = i // batch_size + 1
            
            print(f"\nüì¶ Batch {batch_num}/{total_batches}: Processing {len(batch)} reviews concurrently...")
            batch_start = time.time()
            
            # Process batch with concurrent processing and timeout protection
            batch_results = await self._process_batch_concurrent(batch)
            
            batch_time = time.time() - batch_start
            results.extend(batch_results)
            
            # Enhanced batch summary with routing analysis and performance metrics
            batch_cost = sum(r['cost'] for r in batch_results)
            semantic_hits = len([r for r in batch_results if r['semantic_cache_hit']])
            kv_hits = len([r for r in batch_results if r['kv_cache_hit']])
            success_rate = len(batch_results) / len(batch) * 100
            reviews_per_second = len(batch_results) / batch_time if batch_time > 0 else 0
            
            # Routing distribution for this batch
            routing_distribution = {}
            total_complexity = 0
            for r in batch_results:
                tier = r.get('routing_tier', 'unknown')
                routing_distribution[tier] = routing_distribution.get(tier, 0) + 1
                total_complexity += r.get('complexity_score', 0)
            
            avg_complexity = total_complexity / len(batch_results) if batch_results else 0
            
            # Show smooth progress every 50 reviews or at end
            total_processed = len(results)
            overall_progress = (total_processed / total_reviews) * 100
            
            # Show progress every 50 reviews
            if total_processed % 50 == 0 or total_processed == total_reviews or batch_num % 3 == 0:
                print(f"üìä Processing Progress: {total_processed}/{total_reviews} reviews ({overall_progress:.1f}%)", flush=True)
                if total_processed % 100 == 0 or total_processed == total_reviews:
                    print(f"‚ö° Performance: {reviews_per_second:.2f} rev/s | Success Rate: {success_rate:.0f}% | Cost: ${batch_cost:.6f}", flush=True)
            
            # Compact batch summary (only every few batches for clean output)
            if batch_num % 5 == 0 or batch_num == total_batches:
                print(f"‚úÖ Batch {batch_num}/{total_batches}: {len(batch_results)}/{len(batch)} reviews | {reviews_per_second:.2f} rev/s | ${batch_cost:.6f}")
                if success_rate == 100:
                    print(f"  üéØ PERFECT SUCCESS RATE")
                if reviews_per_second > 2.0:
                    print(f"  ‚ö° HIGH PERFORMANCE")
            
            # Budget check (show only periodically)
            if batch_num % 10 == 0 or batch_num == total_batches:
                current_spend = self.api_optimizer.openrouter_config.current_spend
                budget_percentage = (current_spend / self.max_budget) * 100
                print(f"üí∞ Budget: ${current_spend:.6f} / ${self.max_budget} ({budget_percentage:.1f}%)", flush=True)
                
                if current_spend > self.max_budget * 0.8:
                    print(f"‚ö†Ô∏è Approaching budget limit!", flush=True)
        
        return results
    
    def analyze_routing_distribution(self, reviews: list) -> dict:
        """Analyze projected routing distribution before processing"""
        distribution = {}
        total_projected_cost = 0
        
        print(f"\nüß† SMART ROUTING V2 ANALYSIS:")
        print(f"=" * 40)
        
        for review in reviews:
            routing_result = self.smart_router.route_review(
                review['review_text'], 
                review['category']
            )
            
            tier = routing_result['recommended_tier']
            if tier not in distribution:
                distribution[tier] = {
                    'count': 0,
                    'cost_per_million': routing_result['cost_per_million'],
                    'projected_cost': 0,
                    'avg_complexity': 0,
                    'examples': []
                }
            
            # Calculate projected cost for this review
            estimated_tokens = len(review['review_text'].split()) * 1.3
            review_cost = (estimated_tokens / 1_000_000) * routing_result['cost_per_million']
            
            distribution[tier]['count'] += 1
            distribution[tier]['projected_cost'] += review_cost
            distribution[tier]['avg_complexity'] += routing_result['complexity_analysis']['final']
            total_projected_cost += review_cost
            
            # Store examples
            if len(distribution[tier]['examples']) < 2:
                distribution[tier]['examples'].append({
                    'text': review['review_text'][:60] + '...',
                    'category': review['category'],
                    'complexity': routing_result['complexity_analysis']['final']
                })
        
        # Calculate averages and display
        for tier, data in distribution.items():
            data['avg_complexity'] /= data['count']
            percentage = (data['count'] / len(reviews)) * 100
            
            print(f"{tier}: {data['count']} reviews ({percentage:.1f}%)")
            print(f"  Cost: ${data['cost_per_million']:.2f}/M tokens")
            print(f"  Projected: ${data['projected_cost']:.6f}")
            print(f"  Avg Complexity: {data['avg_complexity']:.2f}")
        
        # Baseline comparison
        baseline_cost = len(reviews) * 150 * (2.50 / 1_000_000)  # GPT-4o baseline
        savings_percentage = ((baseline_cost - total_projected_cost) / baseline_cost * 100)
        
        print(f"\nüí∞ PROJECTED OPTIMIZATION:")
        print(f"Smart Routing: ${total_projected_cost:.6f}")
        print(f"GPT-4o Baseline: ${baseline_cost:.6f}")
        print(f"Projected Savings: {savings_percentage:.1f}%")
        
        return {
            'distribution': distribution,
            'total_projected_cost': total_projected_cost,
            'baseline_cost': baseline_cost,
            'projected_savings_percentage': savings_percentage
        }
    
    def generate_week1_report(self, results: list, total_time: float) -> dict:
        """Generate comprehensive Week 1 report"""
        if not results:
            return {}
        
        # Basic metrics
        total_reviews = len(results)
        total_cost = sum(r['cost'] for r in results)
        semantic_hits = len([r for r in results if r['semantic_cache_hit']])
        kv_hits = len([r for r in results if r['kv_cache_hit']])
        api_calls = len([r for r in results if not r['semantic_cache_hit']])
        
        cache_hit_rate = (semantic_hits / total_reviews * 100) if total_reviews > 0 else 0
        kv_hit_rate = (kv_hits / api_calls * 100) if api_calls > 0 else 0
        
        # Model distribution
        model_counts = {}
        for result in results:
            model = result['model_used']
            model_counts[model] = model_counts.get(model, 0) + 1
        
        # Category breakdown
        category_stats = {}
        for result in results:
            cat = result['category']
            if cat not in category_stats:
                category_stats[cat] = {'count': 0, 'cost': 0.0, 'semantic_hits': 0}
            category_stats[cat]['count'] += 1
            category_stats[cat]['cost'] += result['cost']
            if result['semantic_cache_hit']:
                category_stats[cat]['semantic_hits'] += 1
        
        # Baseline comparison
        baseline_cost = total_reviews * 150 * (10.00 / 1_000_000)  # GPT-4 Turbo baseline
        savings = baseline_cost - total_cost
        savings_percentage = (savings / baseline_cost * 100) if baseline_cost > 0 else 0
        
        return {
            'total_reviews': total_reviews,
            'total_time': total_time,
            'total_cost': total_cost,
            'avg_cost_per_review': total_cost / total_reviews if total_reviews > 0 else 0,
            'api_calls': api_calls,
            'semantic_cache_hit_rate': cache_hit_rate,
            'kv_cache_hit_rate': kv_hit_rate,
            'model_distribution': model_counts,
            'category_breakdown': category_stats,
            'baseline_cost': baseline_cost,
            'savings_amount': savings,
            'savings_percentage': savings_percentage,
            'budget_used': (total_cost / self.max_budget * 100) if self.max_budget > 0 else 0
        }

async def run_week1_full_demo():
    """Run complete Week 1 demo"""
    print("üöÄ WEEK 1 FULL DEMO: 1,000 Amazon Reviews")
    print("Real OpenRouter APIs + Semantic Cache + KV Optimization")
    print("=" * 70)
    
    # Initialize optimizer
    optimizer = Week1FullOptimizer(max_budget=5.00)
    
    # Load 1,000 reviews with smooth progress tracking
    print("\nüì¶ Loading 1,000 Amazon Reviews with Enterprise Progress Tracking")
    print("üîÑ Initializing dataset connection and preparing streaming pipeline...")
    print("=" * 70)
    
    all_reviews = []
    target_total = 1000
    total_start_time = time.time()
    
    # Progressive loading with smooth progress indicators
    categories = ["Electronics", "Books", "Home_and_Garden"]
    reviews_per_category = 334  # ~1000 total / 3 categories
    
    print(f"üöÄ Loading {target_total} reviews across {len(categories)} categories with real-time progress...")
    print(f"üìä Progress will be shown every 50 reviews until 100% completion")
    
    for i, category in enumerate(categories):
        category_start = time.time()
        
        print(f"\nüìÇ Loading {category} reviews... (Category {i+1}/3)", flush=True)
        
        try:
            # Load with custom progress tracking for 1000-review target
            reviews = await optimizer._load_with_progress_tracking(
                category=category,
                sample_size=reviews_per_category,
                current_total=len(all_reviews),
                target_total=target_total
            )
            all_reviews.extend(reviews)
            
            category_time = time.time() - category_start
            overall_progress = (len(all_reviews) / target_total) * 100
            print(f"‚úÖ {category} complete: {len(reviews)} reviews in {category_time:.1f}s | Overall: {overall_progress:.1f}%", flush=True)
            
        except Exception as e:
            print(f"üîÑ Using fallback loading for {category}...", flush=True)
            reviews = optimizer.data_loader.load_sample_data(category, sample_size=reviews_per_category)
            all_reviews.extend(reviews)
            overall_progress = (len(all_reviews) / target_total) * 100
            print(f"‚úÖ {category} loaded: {len(reviews)} reviews | Overall: {overall_progress:.1f}%", flush=True)
    
    total_loading_time = time.time() - total_start_time
    
    # Ensure exactly 1,000 reviews
    week1_reviews = all_reviews[:1000]
    
    print(f"\n‚úÖ DATASET LOADING COMPLETE - 100% SUCCESS!")
    print(f"üìä Loaded: {len(week1_reviews)}/1000 reviews (100.0%)")
    print(f"‚ö° Speed: {len(week1_reviews)/total_loading_time:.1f} reviews/second in {total_loading_time:.1f}s")
    print(f"üöÄ Ready for enterprise processing!")
    print("=" * 70)
    
    # Pre-analyze routing distribution
    routing_analysis = optimizer.analyze_routing_distribution(week1_reviews)
    
    # Process with full optimization
    start_time = time.time()
    print(f"\nüîÑ Starting Week 1 processing at {datetime.now().strftime('%H:%M:%S')}...")
    print(f"‚è±Ô∏è Estimated time: {len(week1_reviews) * 0.3:.0f} seconds based on routing complexity")
    
    results = await optimizer.process_week1_batch(week1_reviews, batch_size=25)
    
    total_time = time.time() - start_time
    print(f"\n‚úÖ Week 1 processing completed in {total_time:.1f} seconds!")
    
    # Generate comprehensive report
    report = optimizer.generate_week1_report(results, total_time)
    
    print(f"\nüìä WEEK 1 FINAL RESULTS:")
    print(f"{'=' * 50}")
    print(f"Reviews Processed: {report['total_reviews']:,}")
    print(f"Total Time: {report['total_time']:.1f} seconds")
    print(f"Total Cost: ${report['total_cost']:.6f}")
    print(f"Cost per Review: ${report['avg_cost_per_review']:.8f}")
    print(f"Budget Used: {report['budget_used']:.1f}%")
    
    print(f"\nüéØ SMART ROUTING V2 OPTIMIZATION:")
    print(f"Projected Cost: ${routing_analysis['total_projected_cost']:.6f}")
    print(f"Actual Cost: ${report['total_cost']:.6f}")
    actual_vs_projected = ((report['total_cost'] - routing_analysis['total_projected_cost']) / routing_analysis['total_projected_cost'] * 100)
    print(f"Routing Accuracy: {actual_vs_projected:+.1f}% vs projection")
    
    print(f"\nüéØ OPTIMIZATION RESULTS:")
    print(f"Semantic Cache Hit Rate: {report['semantic_cache_hit_rate']:.1f}%")
    print(f"KV Cache Benefit Rate: {report['kv_cache_hit_rate']:.1f}%")
    print(f"API Calls Made: {report['api_calls']:,}")
    print(f"Baseline Cost (GPT-4): ${report['baseline_cost']:.6f}")
    print(f"Savings: ${report['savings_amount']:.6f} ({report['savings_percentage']:.1f}%)")
    
    print(f"\nü§ñ MODEL DISTRIBUTION:")
    for model, count in report['model_distribution'].items():
        percentage = (count / report['total_reviews']) * 100
        print(f"  {model}: {count} reviews ({percentage:.1f}%)")
    
    print(f"\nüìÇ CATEGORY PERFORMANCE:")
    for category, stats in report['category_breakdown'].items():
        cache_rate = (stats['semantic_hits'] / stats['count'] * 100)
        print(f"  {category}: {stats['count']} reviews, ${stats['cost']:.6f}, {cache_rate:.1f}% cached")
    
    # Generate LinkedIn summary
    linkedin_summary = optimizer.cost_tracker.generate_linkedin_cost_summary(1)
    
    # Save detailed results
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    results_file = f"week1_results_{timestamp}.json"
    
    with open(results_file, 'w') as f:
        json.dump({
            'metadata': {
                'timestamp': datetime.now().isoformat(),
                'total_reviews': len(results),
                'processing_time': total_time
            },
            'summary': report,
            'linkedin_summary': linkedin_summary,
            'detailed_results': results[:10]  # First 10 for space
        }, f, indent=2)
    
    print(f"\nüìÑ Detailed results saved: {results_file}")
    print(f"\nüìù LinkedIn Summary:")
    print("=" * 50)
    print(linkedin_summary)
    
    print(f"\nüéâ WEEK 1 DEMO COMPLETE!")
    print(f"Ready for LinkedIn series launch with authentic results!")
    
    return results, report

if __name__ == "__main__":
    results, report = asyncio.run(run_week1_full_demo())
    print(f"\nFinal Cost: ${report['total_cost']:.6f}")
    print(f"Budget Safety Factor: {5.00 / report['total_cost']:.0f}x")